# -*- coding: utf-8 -*-
"""Lab3 Kishor.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XvjMxoI2Zv7E2oG61q5DeHMa5wMl9Chu
"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score, classification_report

# Sample dataset
data = {
    'Pregnancies': [5, 2, 7, 0, 1, 4, 2, 8, 3, 6],
    'Glucose': [155, 90, 178, 92, 130, 110, 85, 108, 190, 120],
    'BloodPressure': [70, 64, 60, 70, 42, 72, 55, 65, 68, 88],
    'SkinThickness': [34, 30, 1, 22, 36, 5, 30, 7, 40, 3],
    'Insulin': [10, 15, 20, 85, 180, 30, 100, 12, 500, 25],
    'BMI': [32.8, 27.0, 24.5, 27.3, 41.5, 26.0, 30.2, 36.1, 31.5, 29.0],
    'DiabetesPedigreeFunction': [0.600, 0.370, 0.710, 0.190, 2.100, 0.210, 0.260, 0.145, 0.170, 0.220],
    'Age': [48, 33, 34, 22, 35, 32, 28, 31, 50, 52],
    'Outcome': [1, 0, 1, 0, 1, 0, 0, 0, 1, 1]
}

# Load the dataset
df = pd.DataFrame(data)

# Split the data into features and target
X = df.drop(columns='Outcome')
y = df['Outcome']

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Initialize the Naive Bayes classifier
nb_classifier = GaussianNB()

# Train the model
nb_classifier.fit(X_train, y_train)

# Make predictions
y_pred_nb = nb_classifier.predict(X_test)

# Evaluate the model
accuracy_nb = accuracy_score(y_test, y_pred_nb)
print(f"Naive Bayes Accuracy: {accuracy_nb:.2f}")
print("\nClassification Report:\n", classification_report(y_test, y_pred_nb))

"""2. Using ID3"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, classification_report

# Sample dataset (same as above)
data = {
    'Pregnancies': [5, 2, 7, 0, 1, 4, 2, 8, 3, 6],
    'Glucose': [155, 90, 178, 92, 130, 110, 85, 108, 190, 120],
    'BloodPressure': [70, 64, 60, 70, 42, 72, 55, 65, 68, 88],
    'SkinThickness': [34, 30, 1, 22, 36, 5, 30, 7, 40, 3],
    'Insulin': [10, 15, 20, 85, 180, 30, 100, 12, 500, 25],
    'BMI': [32.8, 27.0, 24.5, 27.3, 41.5, 26.0, 30.2, 36.1, 31.5, 29.0],
    'DiabetesPedigreeFunction': [0.600, 0.370, 0.710, 0.190, 2.100, 0.210, 0.260, 0.145, 0.170, 0.220],
    'Age': [48, 33, 34, 22, 35, 32, 28, 31, 50, 52],
    'Outcome': [1, 0, 1, 0, 1, 0, 0, 0, 1, 1]
}

# Load the dataset
df = pd.DataFrame(data)

# Split the data into features and target
X = df.drop(columns='Outcome')
y = df['Outcome']

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Initialize the Decision Tree classifier
dt_classifier = DecisionTreeClassifier(criterion='entropy', random_state=42)

# Train the model
dt_classifier.fit(X_train, y_train)

# Make predictions
y_pred_dt = dt_classifier.predict(X_test)

# Evaluate the model
accuracy_dt = accuracy_score(y_test, y_pred_dt)
print(f"Decision Tree Accuracy: {accuracy_dt:.2f}")
print("\nClassification Report:\n", classification_report(y_test, y_pred_dt))

"""3. Comparing Them"""

from sklearn.metrics import confusion_matrix, roc_auc_score

# Calculate confusion matrices
conf_matrix_nb = confusion_matrix(y_test, y_pred_nb)
conf_matrix_dt = confusion_matrix(y_test, y_pred_dt)

# Calculate ROC AUC scores
roc_auc_nb = roc_auc_score(y_test, y_pred_nb)
roc_auc_dt = roc_auc_score(y_test, y_pred_dt)

# Print comparison resultsprint("\nNaive Bayes vs Decision Tree Classifier Performance:\n")
print(f"Naive Bayes Accuracy: {accuracy_nb:.2f}")
print(f"Decision Tree Accuracy: {accuracy_dt:.2f}")
print(f"Naive Bayes ROC AUC: {roc_auc_nb:.2f}")
print(f"Decision Tree ROC AUC: {roc_auc_dt:.2f}")

print("\nConfusion Matrix - Naive Bayes:\n", conf_matrix_nb)
print("\nConfusion Matrix - Decision Tree:\n", conf_matrix_dt)